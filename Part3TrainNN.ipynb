{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First imports\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create a random tensor\n",
    "x = torch.rand(4,4, requires_grad=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x**2\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the gradients, you need to run the `.backward` method on a Variable, `z` for example. This will calculate the gradient for `z` with respect to `x`\n",
    "\n",
    "$$\n",
    "\\frac{\\partial z}{\\partial x} = \\frac{\\partial}{\\partial x}\\left[\\frac{1}{n}\\sum_i^n x_i^2\\right] = \\frac{x}{8}\n",
    "$$\n",
    "\n",
    "In this example we n = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = y.mean()\n",
    "z.backward()\n",
    "print(x.grad)\n",
    "print(x*0.125)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data and define the network\n",
    "\n",
    "We'll load the MNIST dataset and define our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize([0.5],[0.5], inplace=True)])\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll build a network with `nn.Sequential` here. Only difference from the last part is I'm not actually using softmax on the output, but instead just using the raw output from the last layer. This is because the output from softmax is a probability distribution. Often, the output will have values really close to zero or really close to one. Due to [inaccuracies with representing numbers as floating points](https://docs.python.org/3/tutorial/floatingpoint.html), computations with a softmax output can lose accuracy and become unstable. To get around this, we'll use the raw output, called the **logits**, to calculate the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for our network\n",
    "input_size = 784\n",
    "hidden_sizes = [128, 64]\n",
    "output_size = 10\n",
    "\n",
    "# Build a feed-forward network\n",
    "model = nn.Sequential(OrderedDict([\n",
    "                      ('fc1', nn.Linear(input_size, hidden_sizes[0])),\n",
    "                      ('relu1', nn.ReLU()),\n",
    "                      ('fc2', nn.Linear(hidden_sizes[0], hidden_sizes[1])),\n",
    "                      ('relu2', nn.ReLU()),\n",
    "                      ('logits', nn.Linear(hidden_sizes[1], output_size))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the network!\n",
    "\n",
    "The first thing we need to do for training is define our loss function. In PyTorch, you'll usually see this as `criterion`. Here we're using softmax output, so we want to use `criterion = nn.CrossEntropyLoss()` as our loss. Later when training, you use `loss = criterion(output, targets)` to calculate the actual loss.\n",
    "\n",
    "We also need to define the optimizer we're using, SGD or Adam, or something along those lines. Here I'll just use SGD with `torch.optim.SGD`, passing in the network parameters and the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01) #lr is learnign rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's consider just one learning step before looping through all the data. The general process with PyTorch:\n",
    "\n",
    "* Make a forward pass through the network to get the logits \n",
    "* Use the logits to calculate the loss\n",
    "* Perform a backward pass through the network with `loss.backward()` to calculate the gradients\n",
    "* Take a step with the optimizer to update the weights\n",
    "\n",
    "Below I'll go through one training step and print out the weights and gradients so you can see how it changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Parameter containing:\n",
      "tensor([[-0.0315,  0.0113, -0.0030,  ..., -0.0283,  0.0346, -0.0038],\n",
      "        [-0.0277,  0.0219, -0.0158,  ...,  0.0278, -0.0135, -0.0305],\n",
      "        [ 0.0024, -0.0276,  0.0306,  ..., -0.0113,  0.0036, -0.0310],\n",
      "        ...,\n",
      "        [-0.0166, -0.0077,  0.0053,  ..., -0.0076, -0.0300,  0.0196],\n",
      "        [-0.0027,  0.0167,  0.0286,  ...,  0.0203, -0.0054,  0.0245],\n",
      "        [ 0.0258, -0.0265, -0.0287,  ..., -0.0203, -0.0078,  0.0091]],\n",
      "       requires_grad=True)\n",
      "Gradient -  tensor([[ 6.7617e-04,  6.7617e-04,  6.7617e-04,  ...,  6.7617e-04,\n",
      "          6.7617e-04,  6.7617e-04],\n",
      "        [-3.1951e-03, -3.1951e-03, -3.1951e-03,  ..., -3.1951e-03,\n",
      "         -3.1951e-03, -3.1951e-03],\n",
      "        [ 2.8656e-03,  2.8656e-03,  2.8656e-03,  ...,  2.8656e-03,\n",
      "          2.8656e-03,  2.8656e-03],\n",
      "        ...,\n",
      "        [-5.9396e-04, -5.9396e-04, -5.9396e-04,  ..., -5.9396e-04,\n",
      "         -5.9396e-04, -5.9396e-04],\n",
      "        [-7.7773e-05, -7.7773e-05, -7.7773e-05,  ..., -7.7773e-05,\n",
      "         -7.7773e-05, -7.7773e-05],\n",
      "        [ 1.5511e-03,  1.5511e-03,  1.5511e-03,  ...,  1.5511e-03,\n",
      "          1.5511e-03,  1.5511e-03]])\n"
     ]
    }
   ],
   "source": [
    "# So this is basically one step of training\n",
    "print(\"Before\", model.fc1.weight)\n",
    "images, labels = next(iter(trainloader))\n",
    "images.resize_(64, 784)\n",
    "\n",
    "# Here we zero out the gradients because in case we would not \n",
    "# gradient from every epoch would cumulate\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Forward pass\n",
    "output = model.forward(images)\n",
    "loss = criterion(output, labels)\n",
    "loss.backward()\n",
    "print(\"Gradient - \", model.fc1.weight.grad)\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated weights -  Parameter containing:\n",
      "tensor([[-0.0315,  0.0113, -0.0030,  ..., -0.0283,  0.0346, -0.0038],\n",
      "        [-0.0277,  0.0219, -0.0157,  ...,  0.0278, -0.0135, -0.0305],\n",
      "        [ 0.0024, -0.0277,  0.0305,  ..., -0.0113,  0.0036, -0.0311],\n",
      "        ...,\n",
      "        [-0.0166, -0.0077,  0.0053,  ..., -0.0076, -0.0299,  0.0196],\n",
      "        [-0.0027,  0.0167,  0.0286,  ...,  0.0203, -0.0054,  0.0245],\n",
      "        [ 0.0258, -0.0265, -0.0288,  ..., -0.0204, -0.0079,  0.0091]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"Updated weights - \", model.fc1.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real training\n",
    "Now we have to put that logic into a loop in order to train on every image in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "for images, labels in trainloader:\n",
    "    print(images.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/3...  Loss: 2.2932\n",
      "Epoch: 1/3...  Loss: 2.2729\n",
      "Epoch: 1/3...  Loss: 2.2529\n",
      "Epoch: 1/3...  Loss: 2.2315\n",
      "Epoch: 1/3...  Loss: 2.2118\n",
      "Epoch: 1/3...  Loss: 2.1828\n",
      "Epoch: 1/3...  Loss: 2.1491\n",
      "Epoch: 1/3...  Loss: 2.1201\n",
      "Epoch: 1/3...  Loss: 2.0831\n",
      "Epoch: 1/3...  Loss: 2.0574\n",
      "Epoch: 1/3...  Loss: 2.0092\n",
      "Epoch: 1/3...  Loss: 1.9585\n",
      "Epoch: 1/3...  Loss: 1.8938\n",
      "Epoch: 1/3...  Loss: 1.8533\n",
      "Epoch: 1/3...  Loss: 1.7820\n",
      "Epoch: 1/3...  Loss: 1.7332\n",
      "Epoch: 1/3...  Loss: 1.6605\n",
      "Epoch: 1/3...  Loss: 1.5799\n",
      "Epoch: 1/3...  Loss: 1.5208\n",
      "Epoch: 1/3...  Loss: 1.4705\n",
      "Epoch: 1/3...  Loss: 1.4004\n",
      "Epoch: 1/3...  Loss: 1.3549\n",
      "Epoch: 1/3...  Loss: 1.2748\n",
      "Epoch: 2/3...  Loss: 0.6569\n",
      "Epoch: 2/3...  Loss: 1.1701\n",
      "Epoch: 2/3...  Loss: 1.1474\n",
      "Epoch: 2/3...  Loss: 1.0847\n",
      "Epoch: 2/3...  Loss: 1.0185\n",
      "Epoch: 2/3...  Loss: 0.9996\n",
      "Epoch: 2/3...  Loss: 0.9430\n",
      "Epoch: 2/3...  Loss: 0.9111\n",
      "Epoch: 2/3...  Loss: 0.8825\n",
      "Epoch: 2/3...  Loss: 0.8574\n",
      "Epoch: 2/3...  Loss: 0.8418\n",
      "Epoch: 2/3...  Loss: 0.7937\n",
      "Epoch: 2/3...  Loss: 0.7884\n",
      "Epoch: 2/3...  Loss: 0.7495\n",
      "Epoch: 2/3...  Loss: 0.7502\n",
      "Epoch: 2/3...  Loss: 0.7292\n",
      "Epoch: 2/3...  Loss: 0.6907\n",
      "Epoch: 2/3...  Loss: 0.6913\n",
      "Epoch: 2/3...  Loss: 0.6875\n",
      "Epoch: 2/3...  Loss: 0.6731\n",
      "Epoch: 2/3...  Loss: 0.6270\n",
      "Epoch: 2/3...  Loss: 0.6470\n",
      "Epoch: 2/3...  Loss: 0.5896\n",
      "Epoch: 3/3...  Loss: 0.0587\n",
      "Epoch: 3/3...  Loss: 0.6058\n",
      "Epoch: 3/3...  Loss: 0.6068\n",
      "Epoch: 3/3...  Loss: 0.5677\n",
      "Epoch: 3/3...  Loss: 0.5795\n",
      "Epoch: 3/3...  Loss: 0.5466\n",
      "Epoch: 3/3...  Loss: 0.5518\n",
      "Epoch: 3/3...  Loss: 0.5531\n",
      "Epoch: 3/3...  Loss: 0.5576\n",
      "Epoch: 3/3...  Loss: 0.5309\n",
      "Epoch: 3/3...  Loss: 0.5444\n",
      "Epoch: 3/3...  Loss: 0.4968\n",
      "Epoch: 3/3...  Loss: 0.5282\n",
      "Epoch: 3/3...  Loss: 0.5263\n",
      "Epoch: 3/3...  Loss: 0.4929\n",
      "Epoch: 3/3...  Loss: 0.4816\n",
      "Epoch: 3/3...  Loss: 0.4964\n",
      "Epoch: 3/3...  Loss: 0.4637\n",
      "Epoch: 3/3...  Loss: 0.4839\n",
      "Epoch: 3/3...  Loss: 0.4970\n",
      "Epoch: 3/3...  Loss: 0.4808\n",
      "Epoch: 3/3...  Loss: 0.4892\n",
      "Epoch: 3/3...  Loss: 0.4721\n",
      "Epoch: 3/3...  Loss: 0.4746\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "print_every = 40\n",
    "steps = 0\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in iter(trainloader):\n",
    "        steps += 1\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images.resize_(images.size()[0], 784)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward and backward passes\n",
    "        output = model.forward(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            print(\"Epoch: {}/{}... \".format(e+1, epochs),\n",
    "                  \"Loss: {:.4f}\".format(running_loss/print_every))\n",
    "            \n",
    "            running_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have to declare number of epochs\n",
    "epochs = 3\n",
    "print_every = 40\n",
    "steps = 0\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in iter(trainloader):\n",
    "        steps += 1\n",
    "        \n",
    "        # here we put image into a vector 28 x 28 = 784\n",
    "        images.resize_(images.shape[0], 784)\n",
    "        \n",
    "        # zero out gradient\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model.forward(images)\n",
    "        # here loss is just a number = scalar tensor\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #we want to extract number from scalar tensor\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if steps & print_every == 0:\n",
    "            print(f\"Epoch: {epoch+1}/{epochs}\",\n",
    "                 f\"Loss: {(running_loss/print_every)}\")\n",
    "            running_loss = 0\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
